{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_1 = \"data/Jester/jester-v1-1.xls\"\n",
    "raw_1 = pd.read_excel(data_path_1, sep=',', header=None)\n",
    "\n",
    "\n",
    "data_path_2 = \"data/Jester/jester-v1-2.xls\"\n",
    "raw_2 = pd.read_excel(data_path_2, sep=',', header=None)\n",
    "\n",
    "\n",
    "data_path_3 = \"data/Jester/jester-v1-3.xls\"\n",
    "raw_3 = pd.read_excel(data_path_3, sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need ratings from (user id, joke id) entry\n",
    "dataframes = [raw_1, raw_2, raw_3]\n",
    "ratings = pd.concat(dataframes)\n",
    "ratings.drop(ratings.columns[0], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jokes with no ratings have been dropped\n",
    "ratings[ratings == 99] = np.nan\n",
    "ratings = ratings.dropna(axis=1, how='all')\n",
    "# reset user id index \n",
    "ratings = ratings.reset_index(drop=True) # shape: 73,421 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = ratings.T.unstack().dropna().to_frame()\n",
    "Xy.columns = [\"ratings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack(Xy.index.values)\n",
    "y = Xy.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = np.sum(y>0)/np.size(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58.5% percent of the labels is in class 1 and 40.5% is in class 0\n",
    "\n",
    "As the split isn't unfavourably imbalanced, I will use the roc_auc metric when binarizing the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoded version using original X\n",
    "# split as in the next cell\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_enc = one_hot_encoder.fit_transform(X)\n",
    "\n",
    "# split train, validation and test (60,20,20)\n",
    "X_trainVal_enc, X_test_enc, X_trainVal, X_test, y_trainVal, y_test = train_test_split(X_enc, X, y, test_size=0.2, random_state=10031996, shuffle=True)\n",
    "\n",
    "X_train_enc, X_val_enc, X_train, X_val, y_train, y_val = train_test_split(X_trainVal_enc, X_trainVal, y_trainVal, test_size=0.25, random_state=10031996, shuffle=True)\n",
    "\n",
    "del X_trainVal_enc, X_trainVal, y_trainVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2481816, 2)\n",
      "(827272, 2)\n",
      "(827272, 2)\n",
      "(2481816, 73521)\n",
      "(827272, 73521)\n",
      "(827272, 73521)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # 2.5 million joke ratings\n",
    "print(X_val.shape) # 0.8 million joke ratings\n",
    "print(X_test.shape) # 0.8 million joke ratings\n",
    "\n",
    "print(X_train_enc.shape) # 2.5 million joke ratings\n",
    "print(X_val_enc.shape) # 0.8 million joke ratings\n",
    "print(X_test_enc.shape) # 0.8 million joke ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary and non binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = y_train>0 # binary\n",
    "y_train_cont = y_train # continuous (-10,10)\n",
    "\n",
    "y_val_bin = y_val>0\n",
    "y_val_cont = y_val\n",
    "\n",
    "y_test_bin = y_test>0\n",
    "y_test_cont = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class_1 = np.sum(y_train_bin,y_val_bin,y_test_bin)\n",
    "# fraction = num_class_1/np.sum(y_train_bin.s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"J1_Xtr\", X_train)\n",
    "np.save(\"J1_XtrEnc\", X_train_enc)\n",
    "np.save(\"J1_Xval\", X_val)\n",
    "np.save(\"J1_XvalEnc\", X_val_enc)\n",
    "np.save(\"J1_Xtest\", X_test)\n",
    "np.save(\"J1_XtestEnc\", X_test_enc)\n",
    "\n",
    "np.save(\"J1_ytrBin\", y_train_bin)\n",
    "np.save(\"J1_ytrCat\", y_train_cont)\n",
    "np.save(\"J1_yvalBin\", y_val_bin)\n",
    "np.save(\"J1_yvalCat\", y_val_cont)\n",
    "np.save(\"J1_ytestBin\", y_test_bin)\n",
    "np.save(\"J1_ytestCat\", y_test_cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
