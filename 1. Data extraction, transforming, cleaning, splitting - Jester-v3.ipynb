{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/Jester/jester-v3-1Only.xls\"\n",
    "ratings = pd.read_excel(data_path, sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first column\n",
    "# not informative\n",
    "# tells the number of jokes rated\n",
    "# can be implied by presence of \"99\" \n",
    "# (specifically column length - number of \"99\")\n",
    "ratings.drop(ratings.columns[0], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jokes with no ratings have been dropped\n",
    "ratings[ratings == 99] = np.nan\n",
    "ratings = ratings.dropna(axis=1, how='all')\n",
    "\n",
    "# reset back other nan to 99\n",
    "ratings = ratings.fillna(value=99.0) # shape: 50692 x 140 (10 jokes not rated)\n",
    "\n",
    "ratings = ratings.reset_index(drop=True) # just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = ratings.T.unstack().dropna().to_frame()\n",
    "Xy.columns = [\"ratings\"]\n",
    "\n",
    "X = np.vstack(Xy.index.values)\n",
    "y = Xy.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = np.sum(y>0)/np.size(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92% percent of the labels is in class 1 and 8% is in class 0\n",
    "\n",
    "This is very risky, so I will be investigating the average precision/recall metric as well as the roc_auc metric (when binarizing the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoded version using original X\n",
    "# split as in the next cell\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_enc = one_hot_encoder.fit_transform(X)\n",
    "\n",
    "# split train, validation and test (60,20,20)\n",
    "X_trainVal_enc, X_test_enc, X_trainVal, X_test, y_trainVal, y_test = train_test_split(X_enc, X, y, test_size=0.2, random_state=10031996, shuffle=True)\n",
    "\n",
    "X_train_enc, X_val_enc, X_train, X_val, y_train, y_val = train_test_split(X_trainVal_enc, X_trainVal, y_trainVal, test_size=0.25, random_state=10031996, shuffle=True)\n",
    "\n",
    "del X_trainVal_enc, X_trainVal, y_trainVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4258128, 2)\n",
      "(1419376, 2)\n",
      "(1419376, 2)\n",
      "(4258128, 50832)\n",
      "(1419376, 50832)\n",
      "(1419376, 50832)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # 4.3 million joke ratings\n",
    "print(X_val.shape) # 1.4 million joke ratings\n",
    "print(X_test.shape) # 1.4 million joke ratings\n",
    "\n",
    "print(X_train_enc.shape) # 4.3 million joke ratings\n",
    "print(X_val_enc.shape) # 1.4 million joke ratings\n",
    "print(X_test_enc.shape) # 1.4 million joke ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary and non binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = y_train>0 # binary\n",
    "y_train_cont = y_train # continuous (-10,10)\n",
    "\n",
    "y_val_bin = y_val>0\n",
    "y_val_cont = y_val\n",
    "\n",
    "y_test_bin = y_test>0\n",
    "y_test_cont = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"J3_Xtr\", X_train)\n",
    "np.save(\"J3_XtrEnc\", X_train_enc)\n",
    "np.save(\"J3_Xval\", X_val)\n",
    "np.save(\"J3_XvalEnc\", X_val_enc)\n",
    "np.save(\"J3_Xtest\", X_test)\n",
    "np.save(\"J3_XtestEnc\", X_test_enc)\n",
    "\n",
    "np.save(\"J3_ytrBin\", y_train_bin)\n",
    "np.save(\"J3_ytrCat\", y_train_cont)\n",
    "np.save(\"J3_yvalBin\", y_val_bin)\n",
    "np.save(\"J3_yvalCat\", y_val_cont)\n",
    "np.save(\"J3_ytestBin\", y_test_bin)\n",
    "np.save(\"J3_ytestCat\", y_test_cont)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
